{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\r\n",
    "import keras.backend as K\r\n",
    "from keras import layers, Model, models\r\n",
    "from keras.utils import plot_model\r\n",
    "import numpy as np\r\n",
    "from keras import callbacks\r\n",
    "import tensorflow as tf\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "# from sklearn.model_selection import cross_val_score\r\n",
    "\r\n",
    "# Baseline model\r\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\r\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2)\r\n",
    "x_train, x_test, x_val = x_train.astype('float32')/255, x_test.astype('float32')/255, x_val.astype('float32')/255\r\n",
    "x_train, x_test, x_val = np.expand_dims(x_train, -1), np.expand_dims(x_test, -1), np.expand_dims(x_val, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\r\n",
    "    model = models.Sequential([\r\n",
    "        layers.Conv2D(32, (3,3), activation='relu', input_shape=(28,28,1)),\r\n",
    "        layers.MaxPooling2D((2,2)),\r\n",
    "        layers.Dropout(0.3),\r\n",
    "        layers.BatchNormalization(),\r\n",
    "        layers.Conv2D(64, (3,3), activation='relu'),\r\n",
    "        layers.MaxPooling2D((2,2)),\r\n",
    "        layers.Dropout(0.3),\r\n",
    "        layers.BatchNormalization(),\r\n",
    "        layers.Conv2D(64, (3,3), activation='relu'),\r\n",
    "        layers.Dropout(0.3),\r\n",
    "        layers.BatchNormalization(),\r\n",
    "        layers.Flatten(),\r\n",
    "        layers.Dense(64, activation='relu'),\r\n",
    "        layers.Dense(10, activation='softmax')\r\n",
    "    ])\r\n",
    "    return model\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\r\n",
    "model = build_model()\r\n",
    "plot_model(model, to_file=\"MinInception.png\", show_shapes=True)\r\n",
    "model.compile(loss='sparse_categorical_crossentropy', metrics=['acc'], optimizer='rmsprop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "375/375 [==============================] - 20s 34ms/step - loss: 0.5449 - acc: 0.8263 - val_loss: 1.8903 - val_acc: 0.4304\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - 9s 23ms/step - loss: 0.0881 - acc: 0.9729 - val_loss: 0.0501 - val_acc: 0.9841\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - 9s 24ms/step - loss: 0.0681 - acc: 0.9786 - val_loss: 0.0410 - val_acc: 0.9877\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - 9s 25ms/step - loss: 0.0564 - acc: 0.9835 - val_loss: 0.0380 - val_acc: 0.9876\n",
      "Epoch 5/100\n",
      "375/375 [==============================] - 9s 23ms/step - loss: 0.0505 - acc: 0.9848 - val_loss: 0.0374 - val_acc: 0.9879\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0004000000189989805.\n",
      "Epoch 6/100\n",
      "375/375 [==============================] - 9s 23ms/step - loss: 0.0423 - acc: 0.9867 - val_loss: 0.0280 - val_acc: 0.9909\n",
      "Epoch 7/100\n",
      "375/375 [==============================] - 9s 24ms/step - loss: 0.0330 - acc: 0.9900 - val_loss: 0.0291 - val_acc: 0.9906\n",
      "Epoch 8/100\n",
      "375/375 [==============================] - 9s 24ms/step - loss: 0.0337 - acc: 0.9896 - val_loss: 0.0290 - val_acc: 0.9904\n",
      "Epoch 9/100\n",
      "375/375 [==============================] - 8s 22ms/step - loss: 0.0343 - acc: 0.9898 - val_loss: 0.0280 - val_acc: 0.9913\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.00016000000759959222.\n",
      "Epoch 10/100\n",
      "375/375 [==============================] - 8s 23ms/step - loss: 0.0253 - acc: 0.9923 - val_loss: 0.0263 - val_acc: 0.9920\n",
      "Epoch 11/100\n",
      "375/375 [==============================] - 8s 22ms/step - loss: 0.0273 - acc: 0.9908 - val_loss: 0.0265 - val_acc: 0.9919\n",
      "Epoch 12/100\n",
      "375/375 [==============================] - 9s 23ms/step - loss: 0.0260 - acc: 0.9910 - val_loss: 0.0252 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 6.40000042039901e-05.\n",
      "Epoch 13/100\n",
      "375/375 [==============================] - 9s 23ms/step - loss: 0.0244 - acc: 0.9922 - val_loss: 0.0251 - val_acc: 0.9920\n",
      "Epoch 14/100\n",
      "375/375 [==============================] - 9s 23ms/step - loss: 0.0277 - acc: 0.9914 - val_loss: 0.0255 - val_acc: 0.9916\n",
      "Epoch 15/100\n",
      "375/375 [==============================] - 9s 23ms/step - loss: 0.0239 - acc: 0.9924 - val_loss: 0.0252 - val_acc: 0.9921\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 2.560000284574926e-05.\n",
      "Epoch 16/100\n",
      "375/375 [==============================] - 8s 23ms/step - loss: 0.0234 - acc: 0.9921 - val_loss: 0.0251 - val_acc: 0.9923\n",
      "Epoch 17/100\n",
      "375/375 [==============================] - 9s 23ms/step - loss: 0.0263 - acc: 0.9919 - val_loss: 0.0252 - val_acc: 0.9921\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00017: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x204b301a8e0>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduce_lr = callbacks.ReduceLROnPlateau(\r\n",
    "    monitor='val_acc', \r\n",
    "    min_lr=1e-6, \r\n",
    "    patience=3, \r\n",
    "    factor=0.4,\r\n",
    "    min_delta=0.005,\r\n",
    "    verbose=1\r\n",
    ")\r\n",
    "es = callbacks.EarlyStopping(\r\n",
    "    min_delta=0.001,\r\n",
    "    patience=5,\r\n",
    "    verbose=1,\r\n",
    "    restore_best_weights=True\r\n",
    ")\r\n",
    "\r\n",
    "tb = callbacks.TensorBoard(\r\n",
    "    histogram_freq=2,\r\n",
    "    write_graph=True,\r\n",
    "    write_images=True\r\n",
    ")\r\n",
    "\r\n",
    "model.fit(\r\n",
    "    x_train, y_train,\r\n",
    "    epochs = 100,\r\n",
    "    batch_size=128,\r\n",
    "    validation_data=(x_val, y_val),\r\n",
    "    callbacks=[reduce_lr, es, tb]\r\n",
    ")\r\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('ml': conda)",
   "name": "python385jvsc74a57bd004a20cc0f25f2654a5fc5715c026c4c293afbc25926c593c301cab56769943bf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}